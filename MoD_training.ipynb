{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from fairscale.nn.model_parallel.initialize import (\n",
    "    initialize_model_parallel,\n",
    "    model_parallel_is_initialized,\n",
    ")\n",
    "from llama.tokenizer import Tokenizer\n",
    "\n",
    "from mixture_of_depths.routing_transformer import ModelArgs, MoDTransformer\n",
    "from mixture_of_depths.train import MoDLlamaTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shivaen\\anaconda3\\envs\\MoD\\lib\\site-packages\\torch\\__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "if not torch.distributed.is_initialized():\n",
    "    # torch.distributed.init_process_group(\"nccl\")\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12345'\n",
    "    torch.distributed.init_process_group(backend='gloo', rank=0, world_size=1)\n",
    "if not model_parallel_is_initialized():\n",
    "    model_parallel_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "    initialize_model_parallel(model_parallel_size)\n",
    "\n",
    "local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "torch.cuda.set_device(local_rank)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 21990\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\"../llama/tokenizer.model\")\n",
    "def collate_fn(batch):\n",
    "    bsz = len(batch)\n",
    "    tokenized_texts = [tokenizer.encode(x['text'], bos=True, eos=True) for x in batch]\n",
    "    max_text_len = max(len(t) for t in tokenized_texts)\n",
    "\n",
    "    pad_id = tokenizer.eos_id\n",
    "    tokens = torch.full((bsz, min(2048, max_text_len)), pad_id, dtype=torch.long)\n",
    "    for k, t in enumerate(tokenized_texts):\n",
    "        tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long)[:2048]\n",
    "    \n",
    "    return tokens[:,:-1], tokens[:,1:]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,  1706,   327,  ...,     2,     2,     2],\n",
       "         [    1,  9038,  2501,  ..., 29890,  3099, 29889],\n",
       "         [    1,  9038,  2501,  ...,     2,     2,     2],\n",
       "         [    1,  9038,  2501,  ...,     2,     2,     2]]),\n",
       " tensor([[ 1706,   327, 29889,  ...,     2,     2,     2],\n",
       "         [ 9038,  2501,   263,  ...,  3099, 29889,     2],\n",
       "         [ 9038,  2501,   263,  ...,     2,     2,     2],\n",
       "         [ 9038,  2501,   263,  ...,     2,     2,     2]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With MoD and Auxiliary Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = ModelArgs(\n",
    "    dim=512,\n",
    "    n_layers=6,\n",
    "    n_heads=8,\n",
    "    vocab_size=tokenizer.n_words,\n",
    "    routing=True,\n",
    "    aux_loss=True\n",
    ")\n",
    "model = MoDTransformer(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53222400"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MoDLlamaTrainer(\n",
    "    params=model_params,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataloader=dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:  18%|█▊        | 1002/5498 [01:16<06:30, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 7.006802941322326\n",
      "Causal Loss at step 1000: 0.08809202676918358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:  36%|███▋      | 2002/5498 [02:32<04:18, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 5.918302805185318\n",
      "Causal Loss at step 2000: 0.06418199791555526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:  55%|█████▍    | 3002/5498 [03:47<03:00, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000: 5.321991624275843\n",
      "Causal Loss at step 3000: 0.05198440214487103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:  73%|███████▎  | 4002/5498 [05:03<01:49, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4000: 4.9382692607045175\n",
      "Causal Loss at step 4000: 0.04592174272070406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:  91%|█████████ | 5002/5498 [06:22<00:45, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5000: 4.626036303830147\n",
      "Causal Loss at step 5000: 0.04173516972358338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 5498/5498 [07:01<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 4.513263336026743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  18%|█▊        | 1002/5498 [01:15<06:33, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 3.236232976078987\n",
      "Causal Loss at step 1000: 0.0156562289170688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  36%|███▋      | 2002/5498 [02:31<04:13, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 3.1664874161481857\n",
      "Causal Loss at step 2000: 0.01575509571362636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  55%|█████▍    | 3002/5498 [03:47<03:02, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000: 3.105056991259257\n",
      "Causal Loss at step 3000: 0.015763346709737863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  73%|███████▎  | 4002/5498 [05:03<01:49, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4000: 3.066151744902134\n",
      "Causal Loss at step 4000: 0.016194940210931236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  91%|█████████ | 5002/5498 [06:21<00:45, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5000: 3.002454901599884\n",
      "Causal Loss at step 5000: 0.01648979005278088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 5498/5498 [07:00<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Loss: 2.990427528263743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  18%|█▊        | 1002/5498 [01:15<06:32, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.80145192360878\n",
      "Causal Loss at step 1000: 0.0125106017353246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  36%|███▋      | 2002/5498 [02:31<04:13, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 2.768246438384056\n",
      "Causal Loss at step 2000: 0.012678612090501702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  55%|█████▍    | 3002/5498 [03:46<03:03, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000: 2.7416327044169106\n",
      "Causal Loss at step 3000: 0.012900318554563759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  73%|███████▎  | 4002/5498 [05:03<01:49, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4000: 2.7311190115809443\n",
      "Causal Loss at step 4000: 0.013410496817494276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  91%|█████████ | 5002/5498 [06:21<00:45, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5000: 2.6926740930080415\n",
      "Causal Loss at step 5000: 0.013704256183304824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 5498/5498 [07:00<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Loss: 2.6920377413287255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  18%|█▊        | 1002/5498 [01:14<06:35, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.6364756326675414\n",
      "Causal Loss at step 1000: 0.011534790724166669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  36%|███▋      | 2002/5498 [02:30<04:15, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 2.615027206659317\n",
      "Causal Loss at step 2000: 0.011711884467717027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  55%|█████▍    | 3002/5498 [03:45<03:01, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000: 2.600178484280904\n",
      "Causal Loss at step 3000: 0.011988362297338124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  73%|███████▎  | 4002/5498 [05:01<01:51, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4000: 2.60011988979578\n",
      "Causal Loss at step 4000: 0.012498831250646616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  91%|█████████ | 5002/5498 [06:19<00:45, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5000: 2.5716913623332975\n",
      "Causal Loss at step 5000: 0.012757879426144064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 5498/5498 [06:58<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Loss: 2.5755449517634443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  18%|█▊        | 1002/5498 [01:14<06:26, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.5731737401485444\n",
      "Causal Loss at step 1000: 0.011133916068880353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  36%|███▋      | 2002/5498 [02:29<04:09, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 2.5584543668627737\n",
      "Causal Loss at step 2000: 0.011319278810551623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  55%|█████▍    | 3002/5498 [03:44<03:04, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 3000: 2.549927330096563\n",
      "Causal Loss at step 3000: 0.011631888091758203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  73%|███████▎  | 4002/5498 [05:00<01:48, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 4000: 2.5555321508049964\n",
      "Causal Loss at step 4000: 0.012148252352315467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  91%|█████████ | 5001/5498 [06:21<00:45, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 5000: 2.53256622800827\n",
      "Causal Loss at step 5000: 0.01245836284031393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 5498/5498 [06:59<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Loss: 2.5387222885478407\n",
      "CPU times: total: 6min 7s\n",
      "Wall time: 35min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train(\n",
    "    epochs=5,\n",
    "    use_aux_loss=model_params.aux_loss,\n",
    "    use_aux_predictor=model.params.aux_routing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With MoD and Auxiliary Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53353728"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = ModelArgs(\n",
    "    dim=512,\n",
    "    n_layers=6,\n",
    "    n_heads=8,\n",
    "    vocab_size=tokenizer.n_words,\n",
    "    routing=True,\n",
    "    aux_routing=True\n",
    ")\n",
    "model = MoDTransformer(model_params)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MoDLlamaTrainer(\n",
    "    params=model_params,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataloader=dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5308e81e0524716ad0940dcac54afca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 6.924468765258789\n",
      "Token Predictor Accuracy at step 1000: 0.9802144169807434\n",
      "Loss at step 2000: 5.814654923915863\n",
      "Token Predictor Accuracy at step 2000: 0.9834375381469727\n",
      "Loss at step 3000: 5.205756803115209\n",
      "Token Predictor Accuracy at step 3000: 0.9811303615570068\n",
      "Loss at step 4000: 4.827160907268524\n",
      "Token Predictor Accuracy at step 4000: 0.978736400604248\n",
      "Loss at step 5000: 4.530920606350898\n",
      "Token Predictor Accuracy at step 5000: 0.9693493843078613\n",
      "Epoch 1/5 - Loss: 4.4247111710646925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913e9d586a7d4b54959de9d01ab637b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 3.2280124650001527\n",
      "Token Predictor Accuracy at step 1000: 0.9690613746643066\n",
      "Loss at step 2000: 3.170233298122883\n",
      "Token Predictor Accuracy at step 2000: 0.9609028697013855\n",
      "Loss at step 3000: 3.1131341084639232\n",
      "Token Predictor Accuracy at step 3000: 0.9612652063369751\n",
      "Loss at step 4000: 3.080255357682705\n",
      "Token Predictor Accuracy at step 4000: 0.9577699899673462\n",
      "Loss at step 5000: 3.0225194420576096\n",
      "Token Predictor Accuracy at step 5000: 0.9523912072181702\n",
      "Epoch 2/5 - Loss: 3.012032274486109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2749ea9ec51f426eb3d95a41b3ec37fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.80890511071682\n",
      "Token Predictor Accuracy at step 1000: 0.9658401012420654\n",
      "Loss at step 2000: 2.776543844342232\n",
      "Token Predictor Accuracy at step 2000: 0.964267909526825\n",
      "Loss at step 3000: 2.751001624822617\n",
      "Token Predictor Accuracy at step 3000: 0.9614712595939636\n",
      "Loss at step 4000: 2.741134049206972\n",
      "Token Predictor Accuracy at step 4000: 0.9604632258415222\n",
      "Loss at step 5000: 2.7065152017354963\n",
      "Token Predictor Accuracy at step 5000: 0.9627573490142822\n",
      "Epoch 3/5 - Loss: 2.7054980094973153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730b66059e744bc7926e83fee7f7f1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.6169092404842376\n",
      "Token Predictor Accuracy at step 1000: 0.9725882411003113\n",
      "Loss at step 2000: 2.5960776077508925\n",
      "Token Predictor Accuracy at step 2000: 0.9690541625022888\n",
      "Loss at step 3000: 2.583292514403661\n",
      "Token Predictor Accuracy at step 3000: 0.9690254926681519\n",
      "Loss at step 4000: 2.5858921572268008\n",
      "Token Predictor Accuracy at step 4000: 0.9694963693618774\n",
      "Loss at step 5000: 2.560883826804161\n",
      "Token Predictor Accuracy at step 5000: 0.9632113575935364\n",
      "Epoch 4/5 - Loss: 2.5656060975176413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee166ceb515547658a0cb3a25b711fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.551059379696846\n",
      "Token Predictor Accuracy at step 1000: 0.9690996408462524\n",
      "Loss at step 2000: 2.539133041083813\n",
      "Token Predictor Accuracy at step 2000: 0.9656355977058411\n",
      "Loss at step 3000: 2.533072443127632\n",
      "Token Predictor Accuracy at step 3000: 0.9659383296966553\n",
      "Loss at step 4000: 2.5428641163706778\n",
      "Token Predictor Accuracy at step 4000: 0.9659696221351624\n",
      "Loss at step 5000: 2.5200535717725754\n",
      "Token Predictor Accuracy at step 5000: 0.9642000794410706\n",
      "Epoch 5/5 - Loss: 2.5262841506410227\n",
      "CPU times: total: 6min 37s\n",
      "Wall time: 36min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train(\n",
    "    epochs=5,\n",
    "    model_dir=\"./models/MoDLlama_predictor/\",\n",
    "    log_path=\"./logs/MoDLlama_predictor_log.txt\",\n",
    "    use_aux_loss=model_params.aux_loss,\n",
    "    use_aux_predictor=model.params.aux_routing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53221888"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = ModelArgs(\n",
    "    dim=512,\n",
    "    n_layers=6,\n",
    "    n_heads=8,\n",
    "    vocab_size=tokenizer.n_words,\n",
    "    routing=False,\n",
    ")\n",
    "model = MoDTransformer(model_params)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MoDLlamaTrainer(\n",
    "    params=model_params,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataloader=dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65618ad97d44791bea8d3edf013810c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 6.869257176876068\n",
      "Loss at step 2000: 5.80399141049385\n",
      "Loss at step 3000: 5.199864533980687\n",
      "Loss at step 4000: 4.810587356686592\n",
      "Loss at step 5000: 4.494121722722054\n",
      "Epoch 1/5 - Loss: 4.381307774953471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3b30fec96a4b5a87d5f2acce2f89d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 3.133148486495018\n",
      "Loss at step 2000: 3.064842033982277\n",
      "Loss at step 3000: 3.006342195947965\n",
      "Loss at step 4000: 2.9690366214215755\n",
      "Loss at step 5000: 2.9042758924722674\n",
      "Epoch 2/5 - Loss: 2.8924330781268486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e173f23d3464736adc1d54eb5da5b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.7258059195280073\n",
      "Loss at step 2000: 2.690865971207619\n",
      "Loss at step 3000: 2.6640439066092174\n",
      "Loss at step 4000: 2.653085547119379\n",
      "Loss at step 5000: 2.6118169929027557\n",
      "Epoch 3/5 - Loss: 2.610617885939986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53d93be80ba4e0a8493ca160a7cbdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.568033074617386\n",
      "Loss at step 2000: 2.544290638566017\n",
      "Loss at step 3000: 2.5286488727728527\n",
      "Loss at step 4000: 2.5275957393050192\n",
      "Loss at step 5000: 2.495972100639343\n",
      "Epoch 4/5 - Loss: 2.4991861418317822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d545ae249099476bba6305e6a45eb3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4:   0%|          | 0/5498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.508699095606804\n",
      "Loss at step 2000: 2.491215365052223\n",
      "Loss at step 3000: 2.4812898535728456\n",
      "Loss at step 4000: 2.485381192624569\n",
      "Loss at step 5000: 2.4586771958351137\n",
      "Epoch 5/5 - Loss: 2.4640085676575887\n",
      "CPU times: total: 8min 39s\n",
      "Wall time: 40min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train(\n",
    "    epochs=5,\n",
    "    model_dir=\"./models/BaselineLlama/\",\n",
    "    log_path=\"./logs/BaselineLlama_log.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
