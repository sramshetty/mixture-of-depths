{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixture_of_depths.generation import MoDLlama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shivaen\\anaconda3\\envs\\MoD\\lib\\site-packages\\torch\\__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 0.58 seconds\n"
     ]
    }
   ],
   "source": [
    "generator = MoDLlama.build(\n",
    "    ckpt_dir=\"./models/BaselineLlama/\",\n",
    "    tokenizer_path=\"../llama/tokenizer.model\",\n",
    "    max_seq_len=2048,\n",
    "    max_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 469 ms\n",
      "Wall time: 1.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generation': 'there was a little girl named Lily. She loved to play outside in the park with her friends. One day, she found a big, big dog on the woods. She saw a big, big bear and a big pond.\\n\\nLily\\'s mom said, \"Mom, we can\\'t you play with your toys?\"\\n\\nLily smiled and said, \"I want to play with you toys and be careful with me.\"\\n\\nLily was happy to have a toy toys. She had a good time in the sky, but her mom said, \"I want to play with it, Lily. It is good toys and have fun.\"\\n\\nLily smiled and said, \"I\\'m sorry, Lily. You can make a big smile on the toy, but it\\'s very fun to be careful. The end.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generator.text_completion(\n",
    "    [\n",
    "        \"Once upon a time,\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loaded in 0.23 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shivaen\\anaconda3\\envs\\MoD\\lib\\site-packages\\torch\\__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "generator = MoDLlama.build(\n",
    "    ckpt_dir=\"./models/MoDLlama/\",\n",
    "    tokenizer_path=\"../llama/tokenizer.model\",\n",
    "    max_seq_len=2048,\n",
    "    max_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 578 ms\n",
      "Wall time: 2.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generation': 'there was a little girl named Lily. She loved to play outside in the park with her mom. One day, she found a big, trayy man in the park. It was a big, tall man.\\n\\nLily was very happy and saw a big tree. She wanted to play with it, but it was too bad. She said, \"Let\\'s go find it to the man.\"\\n\\nLily was very sad. She saw that the man was a very special friend. \"I want to play with you?\" \\n\\nThe little girl smiled and said, \"I want to play with you. Let\\'s go to the park with my mom.\"\\n\\nLily was happy to see the old man. She thought it was so excited and said, \"I can\\'t wait to make a big hug. Let\\'s make you hurt you.\" \\n\\nThe man said, \"I\\'m sorry, I\\'m sorry'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generator.text_completion(\n",
    "    [\n",
    "        \"Once upon a time,\",\n",
    "    ],\n",
    "    max_gen_len=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loaded in 0.24 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shivaen\\anaconda3\\envs\\MoD\\lib\\site-packages\\torch\\__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "generator = MoDLlama.build(\n",
    "    ckpt_dir=\"./models/MoDLlama_predictor/\",\n",
    "    tokenizer_path=\"../llama/tokenizer.model\",\n",
    "    max_seq_len=2048,\n",
    "    max_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 609 ms\n",
      "Wall time: 2.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generation': 'there was a little girl named Lily. She loved to play outside in the park. One day, she found a big, big box in the park. She wanted to go on a big tree.\\n\\nLily saw a big, big, butterfly and she wanted to see it. She picked it up and asked, \"Look, Lily, I want to try to go home.\" Lily felt happy and happy.\\n\\nLily\\'s mom said, \"I\\'m a big hug. I want to be brave and have to do it.\"\\n\\nLily smiled and said, \"I know what to do, Lily. I\\'m sorry for you.\"\\n\\nLily was happy to be careful and thanked the dog for the candy. She said, \"Thank you, Lily. I am happy to do it.\"\\n\\nLily smiled and said, \"I\\'m sorry, Lily. You can be a'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generator.text_completion(\n",
    "    [\n",
    "        \"Once upon a time,\",\n",
    "    ],\n",
    "    max_gen_len=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
